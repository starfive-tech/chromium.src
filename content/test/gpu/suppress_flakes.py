#!/usr/bin/env vpython3
# Copyright 2021 The Chromium Authors
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.
"""Script for finding and suppressing flaky GPU tests.

This relies on ResultDB BigQuery data under the hood, so it requires the `bq`
tool which is available as part of the Google Cloud SDK
https://cloud.google.com/sdk/docs/quickstarts.

Example usage, which finds all failures in the past 5 days. Any tests that
failed more than twice on a configuration is marked as flaky, and any that
failed more than 5 times is marked as failing:

suppress_flakes.py \
  --project chrome-unexpected-pass-data \
  --sample-period 5
"""
import argparse
import os
import sys

CHROMIUM_SRC_DIR = os.path.join(os.path.dirname(__file__), '..', '..', '..')
sys.path.append(os.path.join(CHROMIUM_SRC_DIR, 'testing'))

# pylint: disable=wrong-import-position
from flake_suppressor_common import expectations
from flake_suppressor_common import result_output
from flake_suppressor_common import results as results_module
from flake_suppressor_common import tag_utils as common_tag_utils
from flake_suppressor import gpu_queries
from flake_suppressor import gpu_tag_utils as tag_utils
# pylint: enable=wrong-import-position


def ParseArgs():
  parser = argparse.ArgumentParser(
      description=('Script for automatically suppressing flaky/failing GPU '
                   'Telemetry-based tests.'))
  parser.add_argument('--project',
                      required=True,
                      help=('The billing project to use for BigQuery queries. '
                            'Must have access to the ResultDB BQ tables, e.g. '
                            '"chrome-luci-data.chromium.gpu_ci_test_results".'))
  parser.add_argument('--sample-period',
                      type=int,
                      default=1,
                      help=('The number of days to sample data from.'))
  parser.add_argument('--no-group-by-tags',
                      action='store_false',
                      default=True,
                      dest='group_by_tags',
                      help=('Append added expectations to the end of the file '
                            'instead of attempting to automatically group with '
                            'similar expectations.'))
  parser.add_argument('--no-prompt-for-user-input',
                      action='store_false',
                      default=True,
                      dest='prompt_for_user_input',
                      help=('Generate expectations automatically based on '
                            'thresholds instead of prompting the user each '
                            'time. The user will still need to add associated '
                            'bugs to generated expectations afterwards.'))
  parser.add_argument('--ignore-threshold',
                      type=float,
                      default=0.01,
                      help=('The fraction of failed tests under which flakes '
                            'will be ignored instead of having an expectation '
                            'added when --no-prompt-for-user-input is used.'))
  parser.add_argument('--flaky-threshold',
                      type=float,
                      default=0.5,
                      help=('The fraction of failed tests under which flakes '
                            'will be marked as RetryOnFailure when '
                            '--no-prompt-for-user-input is used. Above this, '
                            'failures will be marked as Failure.'))
  parser.add_argument('--include-all-tags',
                      action='store_true',
                      default=False,
                      help=('Use all tags generated by a configuration when '
                            'creating an expectation rather than attempting '
                            'to only use the most specific one. This should '
                            'only need to be passed if the tags in the '
                            'expectation files are not ordered from least '
                            'specific to most specific.'))
  parser.add_argument('--result-output-file',
                      help=('Output file to store the generated results. If '
                            'not specified, will use a temporary file.'))
  parser.add_argument('--bypass-up-to-date-check',
                      action='store_true',
                      default=False,
                      help=('Bypasses the check that the local expectation '
                            'files are up to date. Only intended for use on '
                            'bots to avoid failures due to potential race '
                            'conditions between updating the checkout and '
                            'running the script.'))
  args = parser.parse_args()

  if not args.prompt_for_user_input:
    if args.ignore_threshold < 0:
      raise ValueError('--ignore-threshold must be positive')
    if args.flaky_threshold < 0:
      raise ValueError('--flaky-threshold must be positive')
    if args.flaky_threshold <= args.ignore_threshold:
      raise ValueError(
          '--flaky-threshold must be greater than --ignore-threshold')

  return args


def main():
  args = ParseArgs()
  common_tag_utils.SetTagUtilsImplementation(tag_utils.GpuTagUtils)
  if not args.bypass_up_to_date_check:
    expectations.AssertCheckoutIsUpToDate()
  querier_instance = gpu_queries.GpuBigQueryQuerier(args.sample_period,
                                                    args.project)
  results = querier_instance.GetFlakyOrFailingCiTests()
  results.extend(querier_instance.GetFlakyOrFailingTryTests())
  aggregated_results = results_module.AggregateResults(results)
  if args.result_output_file:
    with open(args.result_output_file, 'w') as outfile:
      result_output.GenerateHtmlOutputFile(aggregated_results, outfile)
  else:
    result_output.GenerateHtmlOutputFile(aggregated_results)
  print('If there are many instances of failed tests, that may be indicative '
        'of an issue that should be handled in some other way, e.g. reverting '
        'a bad CL.')
  if args.prompt_for_user_input:
    input('\nBeginning of user input section - press any key to continue')
    expectations.IterateThroughResultsForUser(aggregated_results,
                                              args.group_by_tags,
                                              args.include_all_tags)
  else:
    result_counts = querier_instance.GetResultCounts()
    expectations.IterateThroughResultsWithThresholds(
        aggregated_results, args.group_by_tags, result_counts,
        args.ignore_threshold, args.flaky_threshold, args.include_all_tags)
    print('\nGenerated expectations will need to have bugs manually added.')
  print('\nGenerated expectations likely contain conflicting tags that need to '
        'be removed.')


if __name__ == '__main__':
  main()
